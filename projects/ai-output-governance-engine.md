# AI Output Governance Engine

## One-liner
AIアプリを量産するのではなく、**調整コストをゼロに近づけるための制御レイヤー**を作る。

## 何を作りたいか（状態）
- 意識しなくてもベターに傾く環境
- やらなくていい確認作業が自然に消える運用
- 人間の意志力ではなく、仕組み側で品質を維持する設計

## 何を作らないか（非目標）
- 見た目中心のフロント最適化競争
- 予測精度だけを競う単発AIデモ
- RPA的な場当たり自動化の積み上げ

## Core Thesis
**Forecast × 説明責任 × 摩擦最小化**

- Forecast: 問題が起きる前に先回りする
- 説明責任: 根拠・確率・不確実性を残す
- 摩擦最小化: 追加指示・確認・修正の回数を減らす

## なぜ今これが重要か
- UI中心から、AIエージェントがAPIを直接叩く構造へ移行している
- 価値は「画面」よりも「APIの正当性・一貫性・証跡」に移る
- したがって、フロントレスでも強いサービスを設計できる

## 4つの機能レイヤー
1. Distribution Control
- 出力分布の偏り検知（テーマ重複、難易度偏り、選択肢偏り）

2. Drift Detection
- 時間経過による品質劣化検知（優しすぎる出題、トーン変化）

3. Risk / Anomaly Scoring
- 危険領域のスコア化（税務リスク、曖昧性、構造破綻）

4. Human Friction Minimization
- 追加プロンプト不要化、修正回数削減、判断疲労低減

## 実装先（デモケース）
- Expense: スプシ延長で危険点だけ見える「不安フィルター」
- DET: 無限生成ではなく、難易度と分布を制御する学習生成
- WAKARUMADE: 親子摩擦を減らす適温フィードバック

## 評価指標（最小）
- 手動修正回数/週
- 再プロンプト回数/タスク
- 重要ミスの事前検知率
- 判断に要する時間

## DevDegree向けメッセージ
「AIを使ってアプリを作る」のではなく、  
**「AIの不確実性を制御し、人間とAIが共同で責任を取れる基盤を設計する」**。
